{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# SVM Manual Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a one vs one manual implementation of the SVM algorithm. Most of the code is adapted from Matheiu Blondel's GitHub https://gist.github.com/mblondel/586753 which uses kernel implementations such as linear kernel, polynomial kernel and Gaussian kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "from scipy.stats import mode \n",
    "import cupy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import combinations\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The folder name can be modified to whatever you wish\n",
    "results_dir= \"./slcw2_results/\"\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Kernel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Gaussian Kernel\n",
    "def gaussian_kernel_matrix(X1, X2, c=1):\n",
    "    \n",
    "    \"\"\" \n",
    "    Compute gaussian kernel matrix, given data matrices.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    X1 - training data matrix of shape (m, n) where m is the number of training instances and n is the number of features\n",
    "    X2 - matrix of shape (l, n) where l=m if we are generating matrix for training. Otherwise, l is the number of new points we are predicting on.\n",
    "    c - width of Gaussian kernel\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    kernel matrix of dimensions (m, l)\n",
    "    \"\"\"\n",
    "    \n",
    "    B = X1 @ X2.T\n",
    "    norm_sq = np.diagonal(X1@X1.T).reshape(-1, 1) - 2*B + np.diagonal(X2@X2.T).reshape(1, -1)\n",
    "    return np.exp(-1 * c * norm_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def preprocess(dataset, flat=True):\n",
    "    \"\"\" Preprocess dataset by separating labels and image pixels. If flat=True, then each datapoint is a flattened vector. \"\"\"\n",
    "\n",
    "    # Extract labels\n",
    "    y = dataset[:, 0]\n",
    "\n",
    "    # Extract pixel values\n",
    "    x = dataset[:, 1:]\n",
    "\n",
    "    if not flat:\n",
    "        # Reshape into image dimensions\n",
    "        x = x.reshape((x.shape[0], 16, 16))\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def create_subsets(data, labels, classes):\n",
    "    \n",
    "    \"\"\" \n",
    "    Create subsets of the dataset which only contain examples and labels for selected class pairs.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    data - dataset of dimensions (m, n) where m is the number of instances and n is the number of features\n",
    "    labels - true labels for data, must be of shape (m, )\n",
    "    classes - the class pairs to select from the full data matrix to generate data subset. Should be a tuple/list.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    subset_examples - set of data examples corresponding to the desired class pairs\n",
    "    subset_labels - true labels for the subset_examples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find indices of rows with the desired classes\n",
    "    class_1 = np.where(labels == classes[0])\n",
    "    class_2 = np.where(labels == classes[1])\n",
    "    \n",
    "    # select rows from entire dataset\n",
    "    subset_examples = np.concatenate((data[class_1], data[class_2]))\n",
    "    subset_labels = np.concatenate((labels[class_1], labels[class_2]))\n",
    "    \n",
    "    return subset_examples, subset_labels\n",
    "\n",
    "def split_data(inputs, targets, test_proportion, shuffle=None):\n",
    "    \"\"\"\n",
    "    Splits the data into training and test sets.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    inputs : NumPy array of input data. Should be of shape (# examples, # features)\n",
    "    targets : NumPy array of target data. Should be of shape (# examples, 1)\n",
    "    test_proportion : Value between 0 and 1 which specifies how much of the data to use for testing.\n",
    "    shuffle : Optional. Set to True if you want the data shuffled and then split.\n",
    "    seed : Optional. Set for reproducible results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_X : NumPy array of training examples. Should be of shape (# examples, # features)\n",
    "    train_Y : NumPy array of training targets. Should be of shape (# examples, 1)\n",
    "    test_X : NumPy array of testing examples. Should be of shape (# examples, # features)\n",
    "    test_Y : NumPy array of testing targets. Should be of shape (# examples, 1)\n",
    "    \"\"\"\n",
    "  \n",
    "    #Stores the number of data points\n",
    "    nData = inputs.shape[0]\n",
    "\n",
    "    # Shuffle data\n",
    "    if shuffle:\n",
    "        #Generate a shuffled version of the array indices\n",
    "        shuffled_indices = np.random.permutation(nData)\n",
    "        #Shuffle the inputs as per in the array of shuffled indices\n",
    "        shuffled_inputs = inputs[shuffled_indices, :]\n",
    "        shuffled_targets = targets[shuffled_indices]\n",
    "    else:\n",
    "        #If shuffle is set to False then we just work with the data in its original order\n",
    "        shuffled_indices = None\n",
    "        shuffled_inputs = inputs\n",
    "        shuffled_targets = targets\n",
    "\n",
    "    # Calculate the split index based on the specified proportions\n",
    "    split_index = int((1 - test_proportion) * nData)\n",
    "    \n",
    "    # Collect train and test indices\n",
    "    train_idxs = shuffled_indices[:split_index]\n",
    "    test_idxs = shuffled_indices[split_index:]\n",
    "    cache = (train_idxs, test_idxs)\n",
    "\n",
    "    # Select the examples up to the split index to be used as training set\n",
    "    train_X = shuffled_inputs[:split_index]\n",
    "    train_Y = shuffled_targets[:split_index]\n",
    "    # Select the examples from the split index onwards to be used as the test set\n",
    "    test_X = shuffled_inputs[split_index:]\n",
    "    test_Y = shuffled_targets[split_index:]\n",
    "\n",
    "    return train_X, train_Y, test_X, test_Y, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in full dataset = 9298\n",
      "Labels for the full dataset = [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "# Load the full dataset - Save for later when everything works fine\n",
    "full_dataset = np.genfromtxt(\"data/zipcombo.dat\")\n",
    "\n",
    "# Preprocess full dataset\n",
    "x, y = preprocess(full_dataset)\n",
    "\n",
    "# Inpsect the full dataset \n",
    "print(\"Number of records in full dataset = {}\".format(full_dataset.shape[0]))\n",
    "print(\"Labels for the full dataset = {}\".format(np.unique(full_dataset[:, 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prepare SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class multiclass_SVM():\n",
    "    \n",
    "    \"\"\" \n",
    "    \n",
    "    Kernel Perceptron Class. Can be modified to train in one-vs-all (ova) mode or one-vs-one (ovo) mode.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    train_x : training data of shape (m, n) where m is the number of examples and n is number of features\n",
    "    train_y : training labels of shape (m, )\n",
    "    kernel : kernel matrix function\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_features : number of training features\n",
    "    classes : list of unique classes in dataset\n",
    "    classifiers : list of all pairwise combinations of classes\n",
    "    train_x_subsets : list of subsets of data corresponding to class pairs\n",
    "    train_y_subsets : list of labels for data subsets\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    fit - Fits all (n choose 2) classifiers with the SVM model defined in fit_single_classifier\n",
    "    fit_single_classifier - performs SVM algorithm on single classifier\n",
    "    predict - generates predictions on test points\n",
    "    evaluate - computes misclassification error\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train_x, train_y, kernel):\n",
    "        \n",
    "        # Original datasets\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        \n",
    "        # kernel\n",
    "        self.kernel = kernel\n",
    "        \n",
    "        # Dimensions\n",
    "        self.n_features = train_x.shape[1]\n",
    "        \n",
    "        # Number of unique classes in dataset\n",
    "        self.classes = np.unique(train_y)\n",
    "        \n",
    "        # creates all combinations of classes which will be used to design indivitual binary classifiers\n",
    "        self.classifiers = list(combinations(self.classes, 2))\n",
    "\n",
    "        # create data subsets \n",
    "        self.train_x_subsets = []\n",
    "        self.train_y_subsets = []\n",
    "\n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "\n",
    "            # Extract class values\n",
    "            class_1 = classifier[0]\n",
    "            class_2 = classifier[1]\n",
    "\n",
    "            # Create subset\n",
    "            train_x_subset, train_y_subset = create_subsets(train_x, train_y, classifier)\n",
    "            \n",
    "            # Save train_x_subset\n",
    "            self.train_x_subsets.append(train_x_subset)\n",
    "            \n",
    "            # Modify train_y_subset to have {-1, +1} labels\n",
    "            train_y_subset = np.where(train_y_subset == class_1, 1., -1.)\n",
    "            self.train_y_subsets.append(train_y_subset)\n",
    "            \n",
    "        # biases\n",
    "        self.bs = []\n",
    "        \n",
    "        # lagrange multipliers and support vectors\n",
    "        self.alphas = []\n",
    "        self.svs = []\n",
    "        \n",
    "    def fit(self, C=None, verbose=True):\n",
    "        \n",
    "        \"\"\" Fits all (n choose 2) classifiers with the SVM model defined in fit_single_classifier \"\"\"\n",
    "        \n",
    "        cvxopt.solvers.options['show_progress'] = False\n",
    "        \n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "            \n",
    "            # Log end time\n",
    "            s = time.time()\n",
    "            \n",
    "            if verbose:\n",
    "                print(\">>>> Training Classifier {} : {} vs {}\".format(i+1, classifier[0], classifier[1]), end=\"...\")\n",
    "            \n",
    "            # obtain gram matrix and labels for corresponding classifier\n",
    "            X = self.train_x_subsets[i]\n",
    "            y = self.train_y_subsets[i]\n",
    "\n",
    "            # Compute weights for the corresponding classifier\n",
    "            self.fit_single_classifier(X, y, C)\n",
    "            \n",
    "            # Log start time\n",
    "            e = time.time()\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"time taken: {:.5f} s\".format(e - s))\n",
    "            \n",
    "    def fit_single_classifier(self, X, y, C):\n",
    "        \n",
    "        \"\"\" Runs SVM algorithm on single classifier using training data and C parameter \"\"\"\n",
    "        \n",
    "        # Dimensions\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Compute kernel matrix\n",
    "        K = self.kernel(cp.asarray(X), cp.asarray(X)).get()\n",
    "        \n",
    "        # initialize variables needed to solve QP problem\n",
    "        P = cvxopt.matrix(np.outer(y,y)*K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples))\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        \n",
    "        if C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples)*-1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples)*-1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "        \n",
    "        # solve QP problem\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        \n",
    "        # obtain lagrange multipliers\n",
    "        a = np.ravel(solution['x'])\n",
    "        \n",
    "        # support vector are those that have non zero lagrange multipliers\n",
    "        sv = a > 1e-5\n",
    "        \n",
    "        # lagrange multipliers for sv points\n",
    "        self.a = a[sv]\n",
    "        \n",
    "        # x and y values of sv points\n",
    "        self.sv_x = X[sv]\n",
    "        self.sv_y = y[sv] \n",
    "        \n",
    "        # compute weights vector\n",
    "        wx = (cp.asarray(self.a) * cp.asarray(self.sv_y)).reshape(1, -1) @ self.kernel(cp.asarray(self.sv_x), cp.asarray(self.sv_x))\n",
    "        \n",
    "        # compute intercept\n",
    "        b = cp.mean(cp.asarray(self.sv_y) - wx).get()\n",
    "        \n",
    "        # save the b\n",
    "        self.bs.append(b)\n",
    "        self.alphas.append(self.a)\n",
    "        self.svs.append((self.sv_x, self.sv_y))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\" Generates predictions on new points \"\"\"\n",
    "        \n",
    "        # Stores the classes predicted by the k(k-1)/2 indivitual binary classifiers in each row.\n",
    "        # cols correspond to number of test examples\n",
    "        class_matrix = np.zeros((len(self.classifiers), X.shape[0]))\n",
    "        \n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "            \n",
    "            # Extract class information\n",
    "            class_1 = classifier[0]\n",
    "            class_2 = classifier[1]\n",
    "            \n",
    "            # Generate predictions\n",
    "            sv_x, sv_y = self.svs[i]\n",
    "            wx = (cp.asarray(self.alphas[i]) * cp.asarray(sv_y)).reshape(1, -1) @ self.kernel(cp.asarray(sv_x), cp.asarray(X)) \n",
    "            b = cp.asarray(self.bs[i])\n",
    "            pred = wx + b \n",
    "            \n",
    "            # Encode as +1 or -1\n",
    "            pred = np.where(cp.asnumpy(pred) > 0, 1, -1)\n",
    "            \n",
    "            # Convert back to the original k class values\n",
    "            pred = np.where(pred == 1, class_1, class_2)\n",
    "            \n",
    "            # Update class matrix\n",
    "            class_matrix[i, :] = pred\n",
    "            \n",
    "        # Convert to a final predictions vector where each element is the class with maximum vote\n",
    "        class_predictions = mode(class_matrix)[0].squeeze()\n",
    "        \n",
    "        return class_predictions\n",
    "    \n",
    "    def evaluate(self, X, labels):\n",
    "        \n",
    "        \"\"\" Computes misclassification error, given data and true labels \"\"\"\n",
    "        \n",
    "        # Generate predictions\n",
    "        preds = self.predict(X)\n",
    "        \n",
    "        # Check for mistakes\n",
    "        mistakes = np.where(preds != labels, 1.0, 0.0)\n",
    "        \n",
    "        return np.mean(mistakes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Run model for different polynomial values for 20 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perform_multiple_runs(runs,\n",
    "                          kernel_func,\n",
    "                          param_values,\n",
    "                          C_values,\n",
    "                          save_results=False,\n",
    "                          path_to_results=\"\",\n",
    "                          seed=None,\n",
    "                          verbose=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs multiple runs of training with different parameter values.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    runs : number of runs to perform\n",
    "    kernel_func : kernel matrix function\n",
    "    param_values : parameters of kernel to train with\n",
    "    C_values : list of C parameter values to train with\n",
    "    save_results : Set true to save the results\n",
    "    path_to_results : Saves results to provided filepath\n",
    "    seed : to ensure reproducibility of results\n",
    "    verbose : prints outputs while training\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas dataframe of the final results from experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    # Save results here\n",
    "    results = []\n",
    "\n",
    "    # Set a random seed for reproducibility of results\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    for C in C_values:\n",
    "\n",
    "        for p in param_values:\n",
    "\n",
    "            if verbose:\n",
    "                print(\"paramter = {}, C = {}\".format(p, C))\n",
    "                \n",
    "            result = {\"C\":C, \"p\":p, \"Train Error\":0, \"Train Error STD\":0, \"Test Error\":0, \"Test Error STD\":0}\n",
    "\n",
    "            # Save errors for all runs here\n",
    "            train_errors = []\n",
    "            test_errors = []\n",
    "\n",
    "            for run in range(runs):\n",
    "\n",
    "                if verbose:\n",
    "                    print(\">> Run {}\".format(run+1))\n",
    "\n",
    "                # generate random train-test split\n",
    "                train_x, train_y, test_x, test_y, _ = split_data(inputs=x, targets=y, test_proportion=0.20, shuffle=True)\n",
    "\n",
    "                # setup kernel\n",
    "                kernel = lambda X1, X2, eval: kernel_func(X1, X2, p)\n",
    "                \n",
    "                # Train svm model\n",
    "                model = multiclass_SVM(train_x, train_y, kernel)\n",
    "                model.fit(C=C, verbose=False)\n",
    "\n",
    "                # evaluate on train and test set\n",
    "                train_error = model.evaluate(train_x, train_y)\n",
    "                test_error = model.evaluate(test_x, test_y)\n",
    "                train_errors.append(train_error)\n",
    "                test_errors.append(test_error)\n",
    "\n",
    "            # Convert to numpy arrays\n",
    "            train_errors = np.array(train_errors)\n",
    "            test_errors = np.array(test_errors)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Mean Train Error = {}\".format(np.mean(train_errors)))\n",
    "                print(\"Mean Test Error = {}\\n\".format(np.mean(test_errors)))\n",
    "\n",
    "            # Save results\n",
    "            result[\"Train Error\"] = np.mean(train_errors)\n",
    "            result[\"Train Error STD\"] = np.std(train_errors)\n",
    "            result[\"Test Error\"] = np.mean(test_errors)\n",
    "            result[\"Test Error STD\"] = np.std(test_errors)\n",
    "            results.append(result)\n",
    "\n",
    "    # convert matrix to a pandas dataframe for easier visualization\n",
    "    results_df = pd.DataFrame(results, columns=[key for key in results[0].keys()])\n",
    "\n",
    "    # Save results\n",
    "    if save_results:\n",
    "        results_df.to_csv(results_dir+path_to_results, header=True, index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramter = 0.015625, C = 0.1\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.04335170744823878\n",
      "Mean Test Error = 0.059811827956989236\n",
      "\n",
      "paramter = 0.015625, C = 1\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.0015125033611185805\n",
      "Mean Test Error = 0.02556451612903226\n",
      "\n",
      "paramter = 0.015625, C = 10\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.0002352783006184458\n",
      "Mean Test Error = 0.02252688172043011\n",
      "\n",
      "paramter = 0.015625, C = 100\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 9.411132024737833e-05\n",
      "Mean Test Error = 0.024193548387096774\n",
      "\n",
      "paramter = 0.015625, C = 1000\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.0\n",
      "Mean Test Error = 0.022419354838709677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters to run model on \n",
    "c_values = [2.0**-6]\n",
    "C_values = [10**-1, 10**0, 10**1, 10**2, 10**3]\n",
    "kernel = gaussian_kernel_matrix\n",
    "\n",
    "# Run for 20 runs\n",
    "results = perform_multiple_runs(runs=20,\n",
    "                                param_values=c_values,\n",
    "                                kernel_func=kernel,\n",
    "                                C_values=C_values,\n",
    "                                save_results=True,\n",
    "                                path_to_results=\"q7_svm_basic_results_v2.csv\",\n",
    "                                seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C</th>\n",
       "      <th>p</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Train Error STD</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Test Error STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.043352</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.059812</td>\n",
       "      <td>0.003910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.025565</td>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       C         p  Train Error  Train Error STD  Test Error  \\\n",
       "0           0     0.1  0.015625     0.043352         0.000982    0.059812   \n",
       "1           1     1.0  0.015625     0.001513         0.000285    0.025565   \n",
       "2           2    10.0  0.015625     0.000235         0.000058    0.022527   \n",
       "3           3   100.0  0.015625     0.000094         0.000062    0.024194   \n",
       "4           4  1000.0  0.015625     0.000000         0.000000    0.022419   \n",
       "\n",
       "   Test Error STD  \n",
       "0        0.003910  \n",
       "1        0.003942  \n",
       "2        0.003480  \n",
       "3        0.002343  \n",
       "4        0.002607  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "results = pd.read_csv(results_dir+\"q7_svm_basic_results_v2.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(results['C'], results['Train Error'])\n",
    "plt.plot(results['C'], results['Test Error'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Comparing with scikit's implementation (just to check if similar results are obtained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "def perform_multiple_runs(runs,\n",
    "                          kernel_func,\n",
    "                          param_values,\n",
    "                          C_values,\n",
    "                          seed=None,\n",
    "                          verbose=True):\n",
    "\n",
    "    # Save results here\n",
    "    results = []\n",
    "\n",
    "    # Set a random seed for reproducibility of results\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    for C in C_values:\n",
    "\n",
    "        for p in param_values:\n",
    "\n",
    "            if verbose:\n",
    "                print(\"paramter = {}, C = {}\".format(p, C))\n",
    "                \n",
    "            result = {\"C\":C, \"p\":p, \"Train Error\":0, \"Train Error STD\":0, \"Test Error\":0, \"Test Error STD\":0}\n",
    "\n",
    "            # Save errors for all runs here\n",
    "            train_errors = []\n",
    "            test_errors = []\n",
    "\n",
    "            for run in range(runs):\n",
    "\n",
    "                if verbose:\n",
    "                    print(\">> Run {}\".format(run+1))\n",
    "\n",
    "                # generate random train-test split\n",
    "                train_x, train_y, test_x, test_y, _ = split_data(inputs=x, targets=y, test_proportion=0.20, shuffle=True)\n",
    "                \n",
    "                # Train svm model\n",
    "                model = svm.SVC(C=C, kernel=kernel_func, gamma=p, decision_function_shape=\"ovo\")\n",
    "                model.fit(train_x, train_y)\n",
    "                \n",
    "                # Generate predictions on train and test set\n",
    "                train_preds = model.predict(train_x)\n",
    "                test_preds = model.predict(test_x)\n",
    "\n",
    "                train_mistakes = np.where(train_preds != train_y, 1.0, 0.0)\n",
    "                test_mistakes = np.where(test_preds != test_y, 1.0, 0.0)\n",
    "                \n",
    "                # evaluate on train and test set\n",
    "                train_error = np.mean(train_mistakes)\n",
    "                test_error = np.mean(test_mistakes)\n",
    "                train_errors.append(train_error)\n",
    "                test_errors.append(test_error)\n",
    "\n",
    "            # Convert to numpy arrays\n",
    "            train_errors = np.array(train_errors)\n",
    "            test_errors = np.array(test_errors)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Mean Train Error = {}\".format(np.mean(train_errors)))\n",
    "                print(\"Mean Test Error = {}\\n\".format(np.mean(test_errors)))\n",
    "\n",
    "            # Save results\n",
    "            result[\"Train Error\"] = np.mean(train_errors)\n",
    "            result[\"Train Error STD\"] = np.std(train_errors)\n",
    "            result[\"Test Error\"] = np.mean(test_errors)\n",
    "            result[\"Test Error STD\"] = np.std(test_errors)\n",
    "            results.append(result)\n",
    "\n",
    "    # convert matrix to a pandas dataframe for easier visualization\n",
    "    results_df = pd.DataFrame(results, columns=[key for key in results[0].keys()])\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paramter = 0.015625, C = 0.1\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.050813390696423766\n",
      "Mean Test Error = 0.06728494623655915\n",
      "\n",
      "paramter = 0.015625, C = 1\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.0015192255982791072\n",
      "Mean Test Error = 0.02545698924731183\n",
      "\n",
      "paramter = 0.015625, C = 10\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.0002218338262973918\n",
      "Mean Test Error = 0.02228494623655914\n",
      "\n",
      "paramter = 0.015625, C = 100\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 9.411132024737833e-05\n",
      "Mean Test Error = 0.024381720430107525\n",
      "\n",
      "paramter = 0.015625, C = 1000\n",
      ">> Run 1\n",
      ">> Run 2\n",
      ">> Run 3\n",
      ">> Run 4\n",
      ">> Run 5\n",
      ">> Run 6\n",
      ">> Run 7\n",
      ">> Run 8\n",
      ">> Run 9\n",
      ">> Run 10\n",
      ">> Run 11\n",
      ">> Run 12\n",
      ">> Run 13\n",
      ">> Run 14\n",
      ">> Run 15\n",
      ">> Run 16\n",
      ">> Run 17\n",
      ">> Run 18\n",
      ">> Run 19\n",
      ">> Run 20\n",
      "Mean Train Error = 0.0\n",
      "Mean Test Error = 0.02239247311827957\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters to run model on \n",
    "c_values = [2.0**-6]\n",
    "C_values = [10**-1, 10**0, 10**1, 10**2, 10**3]\n",
    "\n",
    "# Run for 20 runs\n",
    "results_2 = perform_multiple_runs(runs=20,\n",
    "                                param_values=c_values,\n",
    "                                kernel_func=\"rbf\",\n",
    "                                C_values=C_values,\n",
    "                                seed=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>C</th>\n",
       "      <th>p</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Train Error STD</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Test Error STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.043352</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.059812</td>\n",
       "      <td>0.003910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.025565</td>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       C         p  Train Error  Train Error STD  Test Error  \\\n",
       "0           0     0.1  0.015625     0.043352         0.000982    0.059812   \n",
       "1           1     1.0  0.015625     0.001513         0.000285    0.025565   \n",
       "2           2    10.0  0.015625     0.000235         0.000058    0.022527   \n",
       "3           3   100.0  0.015625     0.000094         0.000062    0.024194   \n",
       "4           4  1000.0  0.015625     0.000000         0.000000    0.022419   \n",
       "\n",
       "   Test Error STD  \n",
       "0        0.003910  \n",
       "1        0.003942  \n",
       "2        0.003480  \n",
       "3        0.002343  \n",
       "4        0.002607  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>p</th>\n",
       "      <th>Train Error</th>\n",
       "      <th>Train Error STD</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Test Error STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.050813</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.004006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.025457</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.003407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.002580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>0.003038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C         p  Train Error  Train Error STD  Test Error  Test Error STD\n",
       "0     0.1  0.015625     0.050813         0.001241    0.067285        0.004006\n",
       "1     1.0  0.015625     0.001519         0.000255    0.025457        0.003494\n",
       "2    10.0  0.015625     0.000222         0.000064    0.022285        0.003407\n",
       "3   100.0  0.015625     0.000094         0.000062    0.024382        0.002580\n",
       "4  1000.0  0.015625     0.000000         0.000000    0.022392        0.003038"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Run 20 runs of 5 fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def perform_kfoldCV(k, x, y, C, p, kernel_func, shuffle=True, verbose=True):\n",
    "    \n",
    "    \"\"\" \n",
    "    Performs k-fold cross validation for given parameters\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    k - number of folds of CV to perform\n",
    "    x - training data\n",
    "    y - training labels\n",
    "    C - C parameter for SVM\n",
    "    p - parameter to use for kernel\n",
    "    kernel_func - kernel matrix function\n",
    "    shuffle - shuffles data before performing k-fold CV\n",
    "    verbose - prints output logs while running\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cv_error_over_folds - the cross valiation error for each fold of cross validation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract dimensions\n",
    "    m, n = x.shape\n",
    "    \n",
    "    # Configure kernel function to have a specific d value  \n",
    "    kernel = lambda X1, X2: kernel_func(X1, X2, p)\n",
    "\n",
    "    # Shuffle dataset randomly for splitting into groups\n",
    "    if shuffle:\n",
    "        perm = np.random.permutation(m)\n",
    "        x_shuffled = x[perm, :]\n",
    "        y_shuffled = y[perm]\n",
    "    else:\n",
    "        x_shuffled = x\n",
    "        y_shuffled = y\n",
    "\n",
    "    # Split data into k-groups\n",
    "    x_groups = np.array_split(x_shuffled, k)\n",
    "    y_groups = np.array_split(y_shuffled, k)\n",
    "\n",
    "    # Stores the mean CV error over all folds of CV\n",
    "    cv_error_over_folds = 0\n",
    "\n",
    "    for i in range(len(x_groups)):\n",
    "        \n",
    "        if verbose:\n",
    "            print(\">>>> Cross-validation Fold {}\".format(i+1), end=\"...\")\n",
    "\n",
    "        # Use the selected group as \"validation\" set\n",
    "        val_inputs, val_labels = x_groups[i], y_groups[i]\n",
    "\n",
    "        # Use rest of groups as training set\n",
    "        train_inputs = np.vstack([x_groups[j] for j in range(len(x_groups)) if j != i])\n",
    "        train_labels = np.concatenate([y_groups[j] for j in range(len(x_groups)) if j != i])\n",
    "\n",
    "        #-------------------------TRAIN MODEL--------------------------#\n",
    "\n",
    "        # Train model\n",
    "        model = multiclass_SVM(train_inputs, train_labels, kernel)\n",
    "        model.fit(C=C, verbose=False)\n",
    "        cv_error_over_folds += model.evaluate(val_inputs, val_labels)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Done!\")\n",
    "            \n",
    "        #--------------------------------------------------------------#\n",
    "            \n",
    "    #Average the errors\n",
    "    cv_error_over_folds /= k\n",
    "\n",
    "    return cv_error_over_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def perform_multiple_runs_with_kFold(runs,\n",
    "                                     param_values,\n",
    "                                     kernel_func,\n",
    "                                     C_values,\n",
    "                                     k=5,\n",
    "                                     seed=None,\n",
    "                                     verbose=True,\n",
    "                                     save_results=True,\n",
    "                                     path_to_results=\"\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs multiple runs of training with different parameter values.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    param_values : list of parameter values to train on\n",
    "    k : number of folds of CV\n",
    "    C_values : list of C parameters to train with\n",
    "    kernel_func : kernel matrix function\n",
    "    runs : number of runs to perform\n",
    "    seed : to ensure reproducibility of results\n",
    "    verbose : prints outputs while training\n",
    "    save_results : Set true to save the results\n",
    "    path_to_results : Saves results to provided filepath\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas dataframe of the final results from experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set a random seed for reproducibility of results\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Results will be stored here\n",
    "    results = np.zeros((20, 3))\n",
    "\n",
    "    for run in range(runs):\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Run {}\".format(run+1))\n",
    "\n",
    "        # generate random train-test split\n",
    "        train_x, train_y, test_x, test_y, _ = split_data(inputs=x, targets=y, test_proportion=0.20, shuffle=True)\n",
    "\n",
    "        #----------------------------PERFORM k-FOLD CV-------------------------------#\n",
    "        \n",
    "        # I will record the errors for a single run in this vector\n",
    "        grid_search = []\n",
    "    \n",
    "        for C in C_values:\n",
    "\n",
    "            for p in param_values:\n",
    "\n",
    "                if verbose:\n",
    "                    print(\">> C = {}, parameter = {}\".format(C, p))\n",
    "                    \n",
    "                # Perform k-fold CV on the training set\n",
    "                mean_cv_error = perform_kfoldCV(k, train_x, train_y, C, p, kernel_func, verbose=verbose)\n",
    "                \n",
    "                result = {\"C\":C, \"p\":p, \"CV_Error\":mean_cv_error}\n",
    "                \n",
    "                grid_search.append(result)\n",
    "                \n",
    "        #-----FIND BEST HYPERPARAM VALUE AND TRAIN THE WHOLE DATASET WITH THAT------#\n",
    "\n",
    "        idx_least_error = np.argmin([model[\"CV_Error\"] for model in grid_search])\n",
    "        best_p = grid_search[idx_least_error][\"p\"]\n",
    "        best_C = grid_search[idx_least_error][\"C\"]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nBest model params : p = {}, C = {}\".format(best_p, best_C), end=\"...\")\n",
    "\n",
    "        # Set the kernel to have this d*\n",
    "        kernel = lambda X1, X2: kernel_func(X1, X2, best_p)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Training best model\", end=\"...\")\n",
    "\n",
    "        # Fit model on training set\n",
    "        model = multiclass_SVM(train_x, train_y, kernel)\n",
    "        model.fit(C=best_C, verbose=False)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        test_error = model.evaluate(test_x, test_y)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Test Error = {}\\n\".format(test_error))\n",
    "\n",
    "        # Record results\n",
    "        results[run, 0] = best_p\n",
    "        results[run, 1] = best_C\n",
    "        results[run, 2] = test_error\n",
    "\n",
    "    if save_results:\n",
    "        # Convert results matrix to pandas dataframe\n",
    "        results_df = pd.DataFrame(results, columns=[\"best p\", \"best_C\", \"Test Error\"], index=[\"Run {}\".format(run+1) for run in range(runs)])\n",
    "        results_df.to_csv(results_dir+path_to_results, header=True, index=True)\n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.023118279569892472\n",
      "\n",
      "Run 2\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.021505376344086023\n",
      "\n",
      "Run 3\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 10...Training best model...Test Error = 0.026344086021505377\n",
      "\n",
      "Run 4\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 10...Training best model...Test Error = 0.02204301075268817\n",
      "\n",
      "Run 5\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.020967741935483872\n",
      "\n",
      "Run 6\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 10...Training best model...Test Error = 0.02258064516129032\n",
      "\n",
      "Run 7\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.025268817204301075\n",
      "\n",
      "Run 8\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.023655913978494623\n",
      "\n",
      "Run 9\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.023118279569892472\n",
      "\n",
      "Run 10\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.024193548387096774\n",
      "\n",
      "Run 11\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.02043010752688172\n",
      "\n",
      "Run 12\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.026344086021505377\n",
      "\n",
      "Run 13\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 10...Training best model...Test Error = 0.024731182795698924\n",
      "\n",
      "Run 14\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 10...Training best model...Test Error = 0.01989247311827957\n",
      "\n",
      "Run 15\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.024193548387096774\n",
      "\n",
      "Run 16\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.023655913978494623\n",
      "\n",
      "Run 17\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 1000...Training best model...Test Error = 0.02204301075268817\n",
      "\n",
      "Run 18\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.01989247311827957\n",
      "\n",
      "Run 19\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.020967741935483872\n",
      "\n",
      "Run 20\n",
      ">> C = 0.1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 10, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 100, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      ">> C = 1000, parameter = 0.015625\n",
      ">>>> Cross-validation Fold 1...Done!\n",
      ">>>> Cross-validation Fold 2...Done!\n",
      ">>>> Cross-validation Fold 3...Done!\n",
      ">>>> Cross-validation Fold 4...Done!\n",
      ">>>> Cross-validation Fold 5...Done!\n",
      "\n",
      "Best model params : p = 0.015625, C = 100...Training best model...Test Error = 0.024731182795698924\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Range of d values\n",
    "p_values = [2.0**-6]\n",
    "C_values = [10**-1, 10**0, 10**1, 10**2, 10**3]\n",
    "kernel = gaussian_kernel_matrix\n",
    "\n",
    "# Run model for multiple runs with cross validation\n",
    "results_df = perform_multiple_runs_with_kFold(runs=20,\n",
    "                                              param_values=p_values,\n",
    "                                              kernel_func=kernel,\n",
    "                                              C_values=C_values,\n",
    "                                              k=5,\n",
    "                                              seed=231,\n",
    "                                              path_to_results=\"q7_manual_svm_crossval_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean d* ± STD = 392.5 ± 458.7956201323543\n",
      "Mean Test Error ± STD = 0.02298387096774194 ± 0.001995508584779877\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMean d* \\u00B1 STD = {} \\u00B1 {}\".format(results_df[\"best_C\"].mean(), results_df[\"best_C\"].std()))\n",
    "print(\"Mean Test Error \\u00B1 STD = {} \\u00B1 {}\".format(results_df[\"Test Error\"].mean(), results_df[\"Test Error\"].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    \n",
    "    \"\"\" Trains an SVM classifier using a simplified version of the SMO algorithm \"\"\"\n",
    "    \n",
    "    def __init__(self, train_x, train_y, test_x, test_y, kernel_func):\n",
    "        \n",
    "        self.classes = np.unique(train_y)\n",
    "        \n",
    "        # creates all combinations of classes which will be used to design indivitual binary classifiers\n",
    "        self.classifiers = list(combinations(self.classes, 2))\n",
    "\n",
    "        # initialize datasets\n",
    "        self.alphas = []\n",
    "        self.bs = []\n",
    "        self.classifier_K = []  \n",
    "        self.classifier_y = [] \n",
    "        self.train_K = [] \n",
    "        self.train_y = train_y \n",
    "        self.test_K = [] \n",
    "        self.test_y = test_y \n",
    "\n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "\n",
    "            # Extract class values\n",
    "            class_1 = classifier[0]\n",
    "            class_2 = classifier[1]\n",
    "\n",
    "            # Create subset\n",
    "            examples_subset, labels_subset = create_subsets(train_x, train_y, classifier)\n",
    "\n",
    "            # Create sub-kernels for each classifier\n",
    "            classifier_kernel = cp.asnumpy(kernel_func(cp.asarray(examples_subset), cp.asarray(examples_subset), eval=False))\n",
    "\n",
    "            # Create train kernels\n",
    "            train_kernel = cp.asnumpy(kernel_func(cp.asarray(examples_subset), cp.asarray(train_x), eval=True))\n",
    "\n",
    "            # Create test kernel\n",
    "            test_kernel = cp.asnumpy(kernel_func(cp.asarray(examples_subset), cp.asarray(test_x), eval=True))\n",
    "\n",
    "            # Save kernels\n",
    "            self.classifier_K.append(classifier_kernel)\n",
    "            self.train_K.append(train_kernel)\n",
    "            self.test_K.append(test_kernel)\n",
    "\n",
    "            # Convert labels to {+1, -1} encoding.\n",
    "            labels_subset = np.where(labels_subset == class_1, 1, -1)\n",
    "            self.classifier_y.append(labels_subset)\n",
    "\n",
    "            # Initialize weights as 0s\n",
    "            self.alphas.append(np.zeros(len(examples_subset)))\n",
    "            self.bs.append(0)\n",
    "        \n",
    "    def fit(self, C, tol=1e-3, max_passes=5):\n",
    "        \n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "            \n",
    "            s = time.time()\n",
    "            \n",
    "            print(\">>>> Training Classifier {} : {} vs {}\".format(i+1, classifier[0], classifier[1]), end=\"...\")\n",
    "            \n",
    "            K = self.classifier_K[i]\n",
    "            y = self.classifier_y[i]\n",
    "            \n",
    "            alphas, b = self.fit_single_classifier(K, y, C, tol, max_passes)\n",
    "            \n",
    "            self.alphas[i] = alphas\n",
    "            self.bs[i] = b\n",
    "            \n",
    "            e = time.time()\n",
    "            \n",
    "            print(\"time taken: {:.5f} s\".format(e - s))\n",
    "            \n",
    "    def fit_single_classifier(self, K, Y, C, tol, max_passes):\n",
    "        \n",
    "        \"\"\" \n",
    "\n",
    "        Args\n",
    "        ----\n",
    "        X : matrix of training examples where each row is an example and j-th column is j-th feature.\n",
    "        Y : column vector containing 1 for positive examples and -1 for negative examples.\n",
    "        C : regularization parameter for SVM\n",
    "        kernel : function to compute kernel \n",
    "        tol : tolerance value for determining equality of floating point numbers.\n",
    "        max_passes : controls number of iterations.\n",
    "    \n",
    "        \"\"\"\n",
    "        \n",
    "        m = K.shape[0]\n",
    "\n",
    "        # Variables\n",
    "        alphas = np.zeros((m, 1))\n",
    "        b = 0\n",
    "        E = np.zeros((m, 1))\n",
    "        passes = 0\n",
    "        eta = 0\n",
    "        L = 0\n",
    "        H = 0\n",
    "\n",
    "        while passes < max_passes:\n",
    "            \n",
    "            num_changed_alphas = 0\n",
    "\n",
    "            for i in range(m):\n",
    "\n",
    "                # Calculate Ei = f(x_i) - y_i using (2)\n",
    "#                 E[i] = b + np.sum(alphas * Y * K[:, i]) - Y[i]\n",
    "                E[i] = b + (cp.asarray(alphas).T @ (cp.asarray(K[:, i]) * cp.eye(m)) @ cp.asarray(Y)).get() - Y[i]\n",
    "\n",
    "                if ((Y[i]*E[i] < -tol and alphas[i] < C) or (Y[i]*E[i] > tol and alphas[i] > 0)):\n",
    "\n",
    "                    # Select j != i randomly\n",
    "                    j = np.random.randint(0, m)\n",
    "                    while j == i:\n",
    "                        j = np.random.randint(0, m)\n",
    "\n",
    "                    # Calculate Ej = f(x(j)) - y(j) using (2)\n",
    "#                     E[j] = b + np.sum(alphas * Y * K[:, j]) - Y[j]\n",
    "                    E[j] = b + (cp.asarray(alphas).T @ (cp.asarray(K[:, j]) * cp.eye(m)) @ cp.asarray(Y)).get() - Y[j]\n",
    "\n",
    "                    # Save old alphas\n",
    "                    alpha_i_old = alphas[i]\n",
    "                    alpha_j_old = alphas[j]\n",
    "\n",
    "                    # Compute L and H by (10) or (11)\n",
    "                    if (Y[i] == Y[j]):\n",
    "                        L = max(0, alphas[j] + alphas[i] - C)\n",
    "                        H = min(C, alphas[j] + alphas[i])\n",
    "                    else:\n",
    "                        L = max(0, alphas[j] - alphas[i])\n",
    "                        H = min(C, C + alphas[j] - alphas[i])\n",
    "\n",
    "                    if (L == H):\n",
    "                        # continue to next i\n",
    "                        continue\n",
    "                        \n",
    "                    # Compute eta by (14)\n",
    "                    eta = 2 * K[i, j] - K[i, i] - K[j, j]\n",
    "                    \n",
    "                    if (eta >= 0):\n",
    "                        continue\n",
    "\n",
    "                    # Compute and clip new value for alpha j using (12) and (15)\n",
    "                    alphas[j] = alphas[j] - (Y[j] * (E[i] - E[j])) / eta\n",
    "\n",
    "                    # Clip \n",
    "                    alphas[j] = min(H, alphas[j]) \n",
    "                    alphas[j] = min(L, alphas[j])\n",
    "\n",
    "                    # Check if change in alpha is significant\n",
    "                    if (np.abs(alphas[j] - alpha_j_old) < tol):\n",
    "                        # continue to next i\n",
    "                        # replace anyway\n",
    "                        alphas[j] = alpha_j_old\n",
    "                        continue\n",
    "\n",
    "                    # Determine value for alpha i using (16)\n",
    "                    alphas[i] = alphas[i] + Y[i]*Y[j]*(alpha_j_old - alphas[j])\n",
    "\n",
    "                    # Compute b1 and b2 using (17) and (18) respectively\n",
    "                    b1 = b - E[i] - Y[i] * (alphas[i] - alpha_i_old) * K[i, j].T - Y[j] * (alphas[j] - alpha_j_old) * K[i, j].T\n",
    "                    b2 = b - E[j] - Y[i] * (alphas[i] - alpha_i_old) * K[i, j].T - Y[j] * (alphas[j] - alpha_j_old) * K[j, j].T\n",
    "\n",
    "                    # Compute b by (19)\n",
    "                    if (0 < alphas[i] and alphas[i] < C):\n",
    "                        b = b1\n",
    "                    elif (0 < alphas[j] and alphas[j] < C):\n",
    "                        b = b2\n",
    "                    else:\n",
    "                        b = (b1 + b2)/2\n",
    "                        \n",
    "                    num_changed_alphas += 1\n",
    "\n",
    "            if (num_changed_alphas == 0):\n",
    "                passes += 1\n",
    "            else:\n",
    "                passes = 0\n",
    "                \n",
    "        return alphas, b\n",
    "    \n",
    "    def predict(self, K, labels):\n",
    "        \n",
    "        # Stores the classes predicted by the k(k-1)/2 indivitual binary classifiers in each row.\n",
    "        # cols correspond to number of test examples\n",
    "        class_matrix = np.zeros((len(self.classifiers), K[0].shape[1]))\n",
    "        \n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "            \n",
    "            # Extract class information\n",
    "            class_1 = classifier[0]\n",
    "            class_2 = classifier[1]\n",
    "            \n",
    "            # Generate predictions\n",
    "            pred = cp.asarray(self.bs[i]) + (cp.asarray(self.alphas[i]).squeeze() * cp.asarray(labels[i]).T) @ cp.asarray(K[i])\n",
    "            \n",
    "            # Encode as +1 or -1\n",
    "            pred = np.where(cp.asnumpy(pred) > 0, 1, -1)\n",
    "            \n",
    "            # Convert back to the original k class values\n",
    "            pred = np.where(pred == 1, class_1, class_2)\n",
    "            \n",
    "            # Update class matrix\n",
    "            class_matrix[i, :] = pred\n",
    "            \n",
    "        # Convert to a final predictions vector where each element is the class with maximum vote\n",
    "        class_predictions = mode(class_matrix)[0].squeeze()\n",
    "        \n",
    "        return class_predictions\n",
    "    \n",
    "    def evaluate(self, K, labels):\n",
    "        \n",
    "        # Generate predictions\n",
    "        preds = self.predict(K, labels)\n",
    "        \n",
    "        # Check for mistakes\n",
    "        mistakes = np.where(preds != labels, 1.0, 0.0)\n",
    "        \n",
    "        return np.mean(mistakes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
